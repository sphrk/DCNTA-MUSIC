{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZuIDrr7DuTU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import signal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set Device\n",
        "myseed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "device = torch.device(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTZGgerPDuTc",
        "outputId": "373df01e-b6e0-4a8f-966c-8d71ed5edc62"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Notebooks/'\n",
        "RESULTS_PATH = PATH + \"results/\"\n",
        "\n",
        "import sys\n",
        "\n",
        "# sys.path.append(PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T75Y1QHcYVKW"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQwCliT1Tgu-"
      },
      "outputs": [],
      "source": [
        "# from utils import *\n",
        "\n",
        "import torch\n",
        "\n",
        "## ---- Music -----\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "def get_steering_vector(array):\n",
        "    '''\n",
        "        array : np.arange(0, M)\n",
        "    '''\n",
        "    assert len(array.shape) == 1, 'Must be 1-D array'\n",
        "    # convert to col vector\n",
        "    array = array.reshape((-1, 1))\n",
        "    steering_vector = lambda theta : np.exp(-1j * np.pi * array * np.sin((theta)))#np.sin(np.deg2rad(theta)))\n",
        "    return steering_vector\n",
        "\n",
        "## ----- MUSIC -----\n",
        "\n",
        "class MUSIC:\n",
        "    ''' multiple signal classification '''\n",
        "    def __init__(self, steering_vector, angles_grid):\n",
        "        '''\n",
        "            steering_vector   : Function\n",
        "            angles_grid       : numpy Array\n",
        "        '''\n",
        "        self.angles_grid = angles_grid\n",
        "        self.A_grid = steering_vector(angles_grid)\n",
        "        self.AH_grid = self.A_grid.conj().T\n",
        "\n",
        "    def spec(self, R, d):\n",
        "        '''\n",
        "            R: Covatiance Matrix\n",
        "            d: num sources\n",
        "        '''\n",
        "        Q, _, _ = np.linalg.svd(R)\n",
        "        Qn = Q[:, d:]\n",
        "\n",
        "        # a = steering_vector(angles_grid)\n",
        "        # P_MUSIC = 1 / (a.conj().T @ Qn @ Qn.conj().T @ a)\n",
        "        spectrum = 1 / np.linalg.norm(self.AH_grid @ Qn, axis=1)\n",
        "        return spectrum\n",
        "\n",
        "    def estimate(self, R, d):\n",
        "        '''\n",
        "            R: Covatiance Matrix\n",
        "            d: num sources\n",
        "        '''\n",
        "        spectrum = self.spec(R, d)\n",
        "        # finding peaks\n",
        "        doas = signal.find_peaks(spectrum)[0]\n",
        "        doas = self.angles_grid[doas[np.argsort(spectrum[doas])[-d:]]]\n",
        "        return np.sort(doas)\n",
        "\n",
        "\n",
        "\n",
        "## -------------------------------------------------\n",
        "\n",
        "def calc_R(Y, n_snapshots):\n",
        "    return (Y @ Y.conj().T) / n_snapshots\n",
        "\n",
        "## ---- Loss -----\n",
        "\n",
        "def permutations(predDoA):\n",
        "    if len(predDoA) == 0:\n",
        "        return []\n",
        "    if len(predDoA) == 1:\n",
        "        return [predDoA]\n",
        "    perms = []\n",
        "    for i in range(len(predDoA)):\n",
        "       remaining = predDoA[:i] + predDoA[i + 1:]\n",
        "\n",
        "       for perm in permutations(remaining):\n",
        "           perms.append([predDoA[i]] + perm)\n",
        "    return perms\n",
        "\n",
        "PERM = {n:permutations(np.arange(0, n, dtype=np.int32).tolist()) for n in range(2, 6+1)}\n",
        "# perm = PERM[5]\n",
        "def rmspe_torch(Y, Y_hat, D):\n",
        "    if Y.ndim != 2:\n",
        "        if Y.ndim == 1:     Y = Y.unsqueeze(0)\n",
        "        else:               raise Exception('dim must be 2 or 1')\n",
        "    if Y_hat.ndim != 2:\n",
        "        if Y_hat.ndim == 1:     Y_hat = Y_hat.unsqueeze(0)\n",
        "        else:                   raise Exception('dim must be 2 or 1')\n",
        "    # Y_perm = torch.concat([torch.tensor(permutations(y.numpy().tolist())).unsqueeze(1) for y in Y], dim=1)\n",
        "    perm = torch.tensor(PERM[D])\n",
        "    Y_perm = torch.concat([y[perm].unsqueeze(1) for y in Y], dim=1)\n",
        "    e = Y_perm - Y_hat\n",
        "\n",
        "    PI = torch.pi\n",
        "    # betta = PI\n",
        "    e = torch.remainder(e + PI/2, PI) - PI/2\n",
        "    e = torch.norm(e, dim=2)\n",
        "    e = torch.sqrt((e ** 2) / D)\n",
        "    e, _ = torch.min(e, dim=0)\n",
        "    return e\n",
        "\n",
        "def rmspe_numpy(Y, Y_hat, D):\n",
        "    Y = torch.tensor(Y)\n",
        "    Y_hat = torch.tensor(Y_hat)\n",
        "\n",
        "    return rmspe_torch(Y, Y_hat, D).numpy()\n",
        "\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y - y_hat) ** 2)\n",
        "\n",
        "## ---- Base Model -----\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, lr, device=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lr = lr\n",
        "\n",
        "        self.gpu_is_available = False\n",
        "        if device != None:\n",
        "            self.device = device\n",
        "        else:\n",
        "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "        self.device = torch.device(self.device)\n",
        "\n",
        "        self.gpu_is_available = True if self.device.type == 'cuda' else False\n",
        "\n",
        "        self.epoch = 0\n",
        "        self.history = {'train_loss' : [], 'val_loss':[]}\n",
        "\n",
        "    def configure_optimizer(self, optimizer):\n",
        "        self.optim = optimizer(self.parameters(), lr=self.lr)\n",
        "\n",
        "    def prepare_batch(self, batch):\n",
        "        if batch.device != self.device: # self.gpu_is_available:\n",
        "            batch = batch.to(self.device)\n",
        "        return batch\n",
        "\n",
        "    def change_lr(self, lr):\n",
        "        self.lr = lr # self.lr_scheduler(self.lr, self.epoch)\n",
        "        if self.optim:\n",
        "            self.optim.param_groups[0]['lr'] = self.lr\n",
        "\n",
        "    def total_number_of_params(self):\n",
        "        return sum([p.numel() for p in self.parameters()])\n",
        "\n",
        "    def forward(self, X):\n",
        "        y = self.net(X)\n",
        "        return y\n",
        "\n",
        "    def fit(self, max_epoch, train_dataloader, val_dataloader=None, lr_scheduler=None):\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "\n",
        "        for epoch in range(max_epoch):\n",
        "            self.epoch += 1\n",
        "\n",
        "            self.fit_epoch()\n",
        "\n",
        "            if self.epoch % 5 == 0:\n",
        "                print(f\"{self.epoch:<3} | Loss : {self.history['train_loss'][-1]:.8f}\")\n",
        "\n",
        "\n",
        "    def fit_epoch(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def plot(self):\n",
        "        plt.figure(figsize=(5, 3))\n",
        "        plt.plot(self.history['train_loss'], label='train_loss')\n",
        "        if self.history['val_loss'] != []:\n",
        "            plt.plot(self.history['val_loss'], label='val_loss')\n",
        "        plt.grid()\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.legend()\n",
        "\n",
        "    def save(self, fname=None):\n",
        "        if fname == None:\n",
        "            fname = self.__class__.__name__ + '_' + datetime.now().strftime('%Y-%M-%d_%H-%m')\n",
        "        torch.save({\n",
        "            'model_state_dict': self.state_dict(),\n",
        "            'model_history': self.history,\n",
        "            'model_lr': self.lr,\n",
        "            'model_epoch' : self.epoch\n",
        "        }, fname)\n",
        "\n",
        "    def load(self, path):\n",
        "        tmp = torch.load(path, weights_only=False, map_location=torch.device('cpu')) # self.device\n",
        "\n",
        "        self.load_state_dict(tmp['model_state_dict'])\n",
        "        self.to(self.device)\n",
        "\n",
        "        self.history = tmp['model_history']\n",
        "        # self.lr = tmp['model_lr']\n",
        "        self.change_lr(tmp['model_lr'])\n",
        "        self.epoch = tmp['model_epoch']\n",
        "        print('LOAD :', path)\n",
        "\n",
        "def plot_results(x_data, results_dict_list, fig, ax, figsize=(10, 3), black=[]):\n",
        "    fig.set_figwidth(figsize[0])\n",
        "    fig.set_figheight(figsize[1])\n",
        "    # plt.figure(figsize=figsize)\n",
        "    for results_dict in results_dict_list:\n",
        "        for key, value in results_dict.items():\n",
        "            if value == []:     continue\n",
        "            if key in black : continue\n",
        "\n",
        "            symbol = '-^' if key.startswith('model') else '-o'\n",
        "\n",
        "            ax[0].plot(x_data, value, symbol, label=key)\n",
        "            ax[1].semilogy(x_data, value, symbol, label=key)\n",
        "    ax[0].legend(); ax[0].grid()\n",
        "    ax[1].legend(); ax[1].grid()\n",
        "    #         plt.subplot(1, 2, 1); plt.plot(x_data, value, symbol, label=key); plt.legend()\n",
        "    #         plt.subplot(1, 2, 2); plt.semilogy(x_data, value, symbol, label=key); #plt.legend()\n",
        "    # plt.subplot(1, 2, 1); plt.legend(); plt.grid()\n",
        "    # plt.subplot(1, 2, 2); plt.legend(); plt.grid()\n",
        "\n",
        "## -------------------------------------------------\n",
        "SQRT2 = np.sqrt(2)\n",
        "def complex_randn(sigma, shape):\n",
        "    return (sigma / SQRT2) * (np.random.randn(*shape) + 1j * np.random.randn(*shape))\n",
        "\n",
        "def snrdb2snr(snr_db):\n",
        "    return 10 ** (snr_db / 10)\n",
        "\n",
        "def loss_varD(Y, Y_hat, X_d):\n",
        "    return torch.mean(torch.cat([rmspe_torch(y[:di], y_hat[:di], di.item()) for y, y_hat, di in zip(Y, Y_hat, X_d)]))\n",
        "    # .to(device)\n",
        "\n",
        "def total_number_of_params(m):\n",
        "    return sum([p.numel() for p in m.parameters()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TxC8XwwYVKb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux5017mNrifv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osgf9aLOTgsu"
      },
      "outputs": [],
      "source": [
        "class DOA:\n",
        "    def __init__(self, M, array, n_snapshots, angels_grid, steering_vector=None) -> None:\n",
        "        self.M = M\n",
        "        self.n_snapshots = n_snapshots\n",
        "        if steering_vector == None:\n",
        "            self.steering_vector = get_steering_vector(array=array)\n",
        "        else:\n",
        "            self.steering_vector = steering_vector\n",
        "        self.angles_grid = angels_grid\n",
        "        self.A_grid = self.steering_vector(self.angles_grid)\n",
        "\n",
        "    def construct_signal(self, theta, snr, alpha, S=None, X=None):\n",
        "        d = theta.shape[0]\n",
        "\n",
        "        if X is None:\n",
        "            if S is None:\n",
        "                sigma = 10 ** (snr / 10)\n",
        "                S = complex_randn(sigma, (d, self.n_snapshots))\n",
        "            A = self.steering_vector(theta)\n",
        "            A = A / np.linalg.norm(A) # print(np.linalg.norm(A))\n",
        "            X = A @ S\n",
        "\n",
        "        gamma = 1.\n",
        "        n = scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape) + 1j * scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape)\n",
        "        Y = X + n\n",
        "\n",
        "        return S, X, Y\n",
        "\n",
        "    def construct_signal_noise_normal(self, theta, snr, S=None, X=None):\n",
        "        d = theta.shape[0]\n",
        "\n",
        "        if X is None:\n",
        "            if S is None:\n",
        "                sigma = 10 ** (snr / 10)\n",
        "                S = complex_randn(sigma, (d, self.n_snapshots))\n",
        "            A = self.steering_vector(theta)\n",
        "            A = A / np.linalg.norm(A) # print(np.linalg.norm(A))\n",
        "            X = A @ S\n",
        "\n",
        "        n = complex_randn(1., (self.M, self.n_snapshots))\n",
        "        Y = X + n\n",
        "\n",
        "        return S, X, Y\n",
        "\n",
        "    def generate_S_equal_power(self, n_src):\n",
        "        S = complex_randn(1, (n_src, self.n_snapshots))\n",
        "        return S\n",
        "\n",
        "    def generate_S_diff_power(self, n_src, etta_db, S=None):\n",
        "        if S is None:\n",
        "            S = complex_randn(1, (n_src, self.n_snapshots))\n",
        "        etta = 10 ** (np.array(etta_db) / 10)\n",
        "        S = np.diag(np.sqrt(etta)) @ S\n",
        "        return S\n",
        "\n",
        "    def generate_S_coherent_sources(self, n_src, n_coh, coh_idx=None, coh_etta=None, perm=None):\n",
        "        S_indep = self.generate_S_equal_power(n_src - n_coh)\n",
        "        if n_coh == 0:\n",
        "            return S_indep\n",
        "        # print(S_indep.shape)\n",
        "        if coh_idx is None:\n",
        "            coh_idx = np.random.randint(0, n_src-n_coh, n_coh)\n",
        "            # print(coh_idx)\n",
        "        if coh_etta is None:\n",
        "            coh_etta = (np.random.rand(n_coh) * .8 + .1) * np.exp(-1j * np.random.rand(n_coh) * np.pi)\n",
        "\n",
        "        S_coh = np.diag(coh_etta) @ S_indep[coh_idx]\n",
        "        # print(S_coh.shape)\n",
        "        S = np.concatenate((S_indep, S_coh), axis=0)\n",
        "        # print(S.shape)\n",
        "        if perm is None:\n",
        "            S = S[np.random.permutation(S.shape[0])]\n",
        "            # print(np.random.permutation(S.shape[0]))\n",
        "        else:\n",
        "            S = S[perm]\n",
        "        return S\n",
        "\n",
        "    def calc_X(self, S, theta):\n",
        "        A = self.steering_vector(theta)\n",
        "        A = A / np.linalg.norm(A) # print(np.linalg.norm(A))\n",
        "        X = A @ S\n",
        "        return X\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_Y_snr_n(X, snr_db):\n",
        "        snr = 10 ** (snr_db / 10)\n",
        "        sigma = np.sqrt(1 / snr)\n",
        "        n = complex_randn(sigma, X.shape)\n",
        "        Y = X + n\n",
        "        return Y\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_Y_snr_s(X):\n",
        "        n = complex_randn(1, X.shape)\n",
        "        Y = X + n\n",
        "        return Y\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_Y_gsnr_n(X, gsnr_db, alpha):\n",
        "        gsnr = 10 ** (gsnr_db / 10)\n",
        "        gamma = (1 / (gsnr))# ** (1/alpha)))\n",
        "        n = scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape) + 1j * scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape)\n",
        "        Y = X + n\n",
        "        return Y\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_Y_gsnr_s(X, alpha):\n",
        "        gamma = 1.\n",
        "        n = scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape) + 1j * scipy.stats.levy_stable.rvs(alpha, 0, scale=gamma, size=X.shape)\n",
        "        Y = X + n\n",
        "        return Y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmiOwlRIDuTe",
        "outputId": "4f47c42d-6101-46a3-ff38-63b48e7b4e47"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHizuGT9DuTg",
        "outputId": "cb1dbbcc-5dbe-4098-ef71-6be06db23eb2"
      },
      "outputs": [],
      "source": [
        "N_SRC = 5\n",
        "M = 8\n",
        "SNAPSHOTS = 200\n",
        "\n",
        "array = np.arange(0, M)\n",
        "angles_grid = np.arange(-90., 90. + 1e-6, 1)\n",
        "angles_grid = np.deg2rad(angles_grid)\n",
        "N_ANGLES_GRID = angles_grid.shape[0]\n",
        "\n",
        "doa = DOA(M=M , array=array , n_snapshots=SNAPSHOTS , angels_grid=angles_grid)\n",
        "\n",
        "music = MUSIC(doa.steering_vector, doa.angles_grid)\n",
        "\n",
        "N_SRC_MIN = 2\n",
        "N_SRC_MAX = 5\n",
        "# N_SRC_MAX = 2 # diff power\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv4_8C0oVgSe"
      },
      "outputs": [],
      "source": [
        "def flos(Y, d, p=1.1):\n",
        "    N = SNAPSHOTS\n",
        "\n",
        "    y = Y\n",
        "    yT = Y.T\n",
        "    yH = yT.conj()\n",
        "\n",
        "    Rf = (y @ ((np.abs(yT) ** (p-2)) * yH)) / N\n",
        "    theta_hat = music.estimate(Rf, d)\n",
        "    if theta_hat.shape[0] != d:\n",
        "        theta_hat = np.zeros(d)\n",
        "    return theta_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ggStVLuLQE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxlZPGdnDuTh"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Khiq_5OQwc"
      },
      "outputs": [],
      "source": [
        "# data class\n",
        "class Doa_Data:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def gsnr_eq_pow(d, theta, gsnr, alpha):\n",
        "        ## eq pow - snr - control NOISE\n",
        "        S = doa.generate_S_equal_power(d)\n",
        "        X = doa.calc_X(S, theta)\n",
        "        Y = doa.calc_Y_gsnr_n(X, gsnr, alpha)\n",
        "        return X, Y\n",
        "\n",
        "    @staticmethod\n",
        "    def snr_eq_pow(d, theta, snr):\n",
        "        # S, X, Y = doa.construct_signal_noise_normal(theta, snr)# , S=None, X=None)\n",
        "\n",
        "        ## eq pow - snr - control noise\n",
        "        S = doa.generate_S_equal_power(d)\n",
        "        X = doa.calc_X(S, theta)\n",
        "        Y = doa.calc_Y_snr_n(X, snr)\n",
        "        return X, Y\n",
        "\n",
        "    @staticmethod\n",
        "    def gsnr_diff_pow(d, theta, etta, alpha):\n",
        "        ## diff pow - gsnr - control signal\n",
        "        # etta = np.ones(d) * gsnr\n",
        "        S = doa.generate_S_diff_power(d, etta)\n",
        "        X = doa.calc_X(S, theta)\n",
        "        # Y = doa.calc_Y_gsnr_n(X, gsnr, alpha)\n",
        "        Y = doa.calc_Y_gsnr_s(X, alpha)\n",
        "        return X, Y\n",
        "\n",
        "    @staticmethod\n",
        "    def gsnr_eq_pow_coherent(n_src, n_coh, theta, gsnr, alpha):\n",
        "        ## coherent sources - gsnr\n",
        "        S = doa.generate_S_coherent_sources(n_src, n_coh, coh_idx=None, coh_etta=None, perm=None)\n",
        "        X = doa.calc_X(S, theta)\n",
        "        Y = doa.calc_Y_gsnr_n(X, gsnr, alpha)\n",
        "        return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJgDw9qEmmPt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5z7QUYtLovw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy-51kFlORm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzOJj8KJDuTl"
      },
      "outputs": [],
      "source": [
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "class Create_Dataset:\n",
        "    def __init__(self, n_train, n_val, n_test,\n",
        "                doa,\n",
        "                eq_pow = True,\n",
        "                gaussian_noise = False,\n",
        "                d = 5,\n",
        "                # variable_d=True, fix_d=None,\n",
        "                # with_noise=True,\n",
        "                snr=None,\n",
        "                alpha=None, gsnr=None,\n",
        "                is_coherent=False):\n",
        "\n",
        "        size = n_train + n_val + n_test\n",
        "\n",
        "        doa_data = Doa_Data()\n",
        "\n",
        "        # self.doa = doa\n",
        "        snapshots = doa.n_snapshots\n",
        "\n",
        "        # (Batch, 2*M, T) # 2*M : real & imag\n",
        "        data_X = np.zeros((size, 2*M, snapshots), dtype=np.float32)\n",
        "        # data_X_d = np.zeros(size, dtype=np.int32)\n",
        "        # if variable_d:\n",
        "        #     data_d = np.random.randint(N_SRC_MIN, N_SRC_MAX+1, size)\n",
        "        # else:\n",
        "        #     if fix_d == None:\n",
        "        #         raise Exception('fix d is None')\n",
        "            # data_d = np.ones(size, dtype=np.int32) * fix_d\n",
        "        data_d = np.ones(size, dtype=np.int32) * d\n",
        "\n",
        "        data_Rx = np.zeros((size, 2, M, M), dtype=np.float32)\n",
        "        data_Y = np.ones((size, N_SRC_MAX), dtype=np.float32) * np.pi\n",
        "\n",
        "        if eq_pow:\n",
        "            print('Eq Power')\n",
        "            if is_coherent:\n",
        "                print('**** COHERENT ****')\n",
        "        else:\n",
        "            print('Diff Power')\n",
        "\n",
        "        if gaussian_noise:\n",
        "            if snr is None:    raise Exception('snr is none')\n",
        "            print('Gaussian Noise')\n",
        "        else:\n",
        "            print('Alpha Stable Noise')\n",
        "            if gsnr is None:    raise Exception('gsnr is none')\n",
        "            if alpha is None:   raise Exception('alpha is none')\n",
        "\n",
        "            ALPHA = np.array([1.5, 2])\n",
        "            alpha = ALPHA[np.random.randint(0, len(ALPHA), size)]\n",
        "\n",
        "            if eq_pow:\n",
        "                pass\n",
        "            else:\n",
        "                GSNR = np.array([5., 10., 15.])\n",
        "                etta = GSNR[np.random.randint(0, len(GSNR), (size, d))]\n",
        "\n",
        "\n",
        "        for i in tqdm(range(size)):\n",
        "            # snr = np.random.randint(-20, 20+1)\n",
        "            # snr = 10\n",
        "            d = data_d[i]\n",
        "            theta = np.pi * (np.random.rand(d) - .5)\n",
        "            # theta = np.sort(theta)\n",
        "\n",
        "            if eq_pow:\n",
        "                if gaussian_noise:\n",
        "                    snr = 10.\n",
        "                    raise Exception('qqqq')\n",
        "                    X, Y = doa_data.snr_eq_pow(d, theta, snr)\n",
        "                else:\n",
        "                    # g = [10., 15.]\n",
        "                    # g = [5., 10., 15.]\n",
        "                    gsnr = 10. #= g[np.random.randint(0, 3)]\n",
        "                    # a = [1.5, 2]\n",
        "                    # alpha = a[np.random.randint(0, 2)]\n",
        "\n",
        "                    if is_coherent:\n",
        "                        ## COHERENT\n",
        "                        n_src, n_coh = 5, np.random.randint(0, 2)\n",
        "                        X, Y = doa_data.gsnr_eq_pow_coherent(n_src, n_coh, theta, gsnr, alpha[i])\n",
        "                        # print('****')\n",
        "                    else:\n",
        "                        ## NON COH\n",
        "                        X, Y = doa_data.gsnr_eq_pow(d, theta, gsnr, alpha[i]) #alpha[np.random.randint(0, len_alpha)]\n",
        "\n",
        "            else:\n",
        "                if gaussian_noise:\n",
        "                    raise Exception(NotImplemented)\n",
        "                else:\n",
        "                    # raise Exception(NotImplemented)\n",
        "                    # a = [1.5, 2]\n",
        "                    # alpha = a[np.random.randint(0, 2)]\n",
        "                    # print('.')\n",
        "                    X, Y = doa_data.gsnr_diff_pow(d, theta, etta[i], alpha[i])\n",
        "\n",
        "                    # S = doa.generate_S_diff_power(d, etta)\n",
        "                    # X = doa.calc_X(S, theta)\n",
        "                    # # Y = doa.calc_Y_gsnr_n(X, gsnr, alpha)\n",
        "                    # Y = doa.calc_Y_gsnr_s(X, alpha)\n",
        "\n",
        "            Rx = calc_R(X, snapshots)\n",
        "\n",
        "            data_X[i] = np.concatenate((np.real(Y), np.imag(Y)), axis=0)#.swapaxes(0, 1)\n",
        "            data_Rx[i][0] = np.real(Rx); data_Rx[i][1] = np.imag(Rx)\n",
        "            data_Y[i][:d] = theta\n",
        "\n",
        "        data_X = torch.tensor(data_X)\n",
        "        data_d = torch.tensor(data_d, dtype=torch.long)\n",
        "        data_Rx = torch.tensor(data_Rx)\n",
        "        data_Y = torch.tensor(data_Y)\n",
        "        print(data_X.shape, data_Y.shape)\n",
        "\n",
        "        indices = np.random.permutation(data_X.shape[0])\n",
        "        train_indices = indices[:n_train]\n",
        "        val_indices = indices[n_train: n_train + n_val]\n",
        "        test_indices = indices[n_train + n_val:]\n",
        "\n",
        "        self.traindata_X = data_X[train_indices]\n",
        "        self.traindata_d = data_d[train_indices]\n",
        "        self.traindata_Rx = data_Rx[train_indices]\n",
        "        self.traindata_Y = data_Y[train_indices]\n",
        "\n",
        "        self.val_X = data_X[val_indices]\n",
        "        self.val_d = data_d[val_indices]\n",
        "        self.val_Rx = data_Rx[val_indices]\n",
        "        self.val_Y = data_Y[val_indices]\n",
        "\n",
        "        self.test_X = data_X[test_indices]\n",
        "        self.test_d = data_d[test_indices]\n",
        "        self.test_Rx = data_Rx[test_indices]\n",
        "        self.test_Y = data_Y[test_indices]\n",
        "\n",
        "        print(f\"train X: {self.traindata_X.shape}, train Y: {self.traindata_Y.shape}\")\n",
        "        print(f\"val X: {self.val_X.shape}, val Y: {self.val_Y.shape}\")\n",
        "        print(f\"test X: {self.test_X.shape}, test Y: {self.test_Y.shape}\")\n",
        "\n",
        "\n",
        "    def get_train_dataloader(self, batch_size, shuffle=True):\n",
        "        train_dataloader = torch.utils.data.DataLoader(list(zip(self.traindata_X, self.traindata_d, self.traindata_Rx, self.traindata_Y)), batch_size, shuffle=shuffle)\n",
        "        return train_dataloader\n",
        "\n",
        "    def get_val_dataloader(self, batch_size, shuffle=False):\n",
        "        val_dataloader = torch.utils.data.DataLoader(list(zip(self.val_X, self.val_d, self.val_Rx, self.val_Y)), batch_size, shuffle=shuffle)\n",
        "        return val_dataloader\n",
        "\n",
        "    def get_test_dataloader(self, batch_size, shuffle=False):\n",
        "        test_dataloader = torch.utils.data.DataLoader(list(zip(self.test_X, self.test_d, self.test_Rx, self.test_Y)), batch_size, shuffle=shuffle)\n",
        "        return test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMozrxfkG8kx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y16gdhfb0h2",
        "outputId": "223d6032-5430-4cae-ff13-7045cc23be63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "kQrbyOkiDuTn",
        "outputId": "5eada0b4-3034-4ce4-feb4-48a7c3e38ece"
      },
      "outputs": [],
      "source": [
        "doa.n_snapshots = SNAPSHOTS\n",
        "\n",
        "N_TRAIN = 150_000 # 50_000\n",
        "N_VAL = 32_000\n",
        "N_TEST = 32_000\n",
        "\n",
        "N_SRC = 5;  D = N_SRC\n",
        "\n",
        "\n",
        "## ALPHA STABLE (Eq Pow)\n",
        "da_music_data = Create_Dataset(N_TRAIN, N_VAL, N_TEST, doa,\n",
        "                eq_pow = True,\n",
        "                gaussian_noise = False,\n",
        "                d = 5,\n",
        "                snr=None,\n",
        "                gsnr=10., alpha=[1.5, 2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUBa8SPz5b7n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mx8B_jV8C4S",
        "outputId": "33f61c82-60b5-4307-8d7d-f1128a05b853"
      },
      "outputs": [],
      "source": [
        "doa.n_snapshots = SNAPSHOTS\n",
        "\n",
        "N_TRAIN = 100_000\n",
        "N_VAL = 21_000\n",
        "N_TEST = 21_000\n",
        "# size = N_TRAIN + 25_000\n",
        "\n",
        "# '''\n",
        "#     \"N_SRC_MAX\" must be changed to 2\n",
        "# '''\n",
        "## ALPHA STABLE - Diff Pow\n",
        "da_music_data = Create_Dataset(N_TRAIN, N_VAL, N_TEST, doa,\n",
        "                eq_pow = False,\n",
        "                gaussian_noise = False,\n",
        "                d = 2,\n",
        "                snr=None,\n",
        "                gsnr=10., alpha=[1.5, 2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbyVcv7ysRFk",
        "outputId": "b647c26d-fc4e-42f6-ca72-a71af47467f9"
      },
      "outputs": [],
      "source": [
        "doa.n_snapshots = SNAPSHOTS\n",
        "\n",
        "# N_TRAIN = 100_000 # 50_000\n",
        "# size = N_TRAIN + 25_000\n",
        "\n",
        "N_TRAIN = 150_000 # 50_000\n",
        "N_VAL = 32_000\n",
        "N_TEST = 32_000\n",
        "# size = N_TRAIN + 30_000\n",
        "\n",
        "N_SRC = 5;  D = N_SRC\n",
        "\n",
        "## ALPHA STABLE - Coh\n",
        "da_music_data = Create_Dataset(N_TRAIN, N_VAL, N_TEST, doa,\n",
        "                eq_pow = True, is_coherent=True,\n",
        "                gaussian_noise = False,\n",
        "                d = 5,\n",
        "                snr=None,\n",
        "                gsnr=10., alpha=[1.5, 2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kz_OOvoDuTo",
        "outputId": "ef5ab5f4-2e97-4d9b-ff05-9348bf4a5685"
      },
      "outputs": [],
      "source": [
        "print(BATCH_SIZE)\n",
        "train_dataloader = da_music_data.get_train_dataloader(BATCH_SIZE)\n",
        "val_dataloader = da_music_data.get_val_dataloader(BATCH_SIZE)\n",
        "test_dataloader = da_music_data.get_test_dataloader(BATCH_SIZE * 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTldKvb7DuTq",
        "outputId": "7fcaa43d-8bf6-44ff-e421-fb91cb8f70ea"
      },
      "outputs": [],
      "source": [
        "# X, X_d, X_R, Y = next(iter(train_dataloader))\n",
        "# X.shape, X_d.shape, X_R.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm5OrL5Y55MS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UucLvJcw55MU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdCEuCHnDuTq"
      },
      "outputs": [],
      "source": [
        "# DATE = '0000-00-00'\n",
        "\n",
        "# def save_model(date, model, model_name, n_traindata, batch_size, save1=True, save2=True):\n",
        "#     fname = '{date}_{model_name}_{n_traindata}_B{batchsize}_E{epoch}_lr{lr}.pth'.format(\n",
        "#         date=date, model_name=model_name, n_traindata=n_traindata, batchsize=batch_size, epoch=model.epoch, lr=model.lr\n",
        "#     )\n",
        "#     print(fname)\n",
        "#     if save1:   model.save(fname)\n",
        "#     else: print('**** 1-NOT SAVED ****')\n",
        "#     if save2:   model.save(RESULTS_PATH + fname)\n",
        "#     else: print('**** 2-NOT SAVED ****')\n",
        "\n",
        "# # save_model(DATE, da_music, 'nn', '50k', BATCH_SIZE) # Ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TqbIs26e7Ic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-91thowXYVKj"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LaRszFIueTh"
      },
      "source": [
        "## DA_MUSIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa6hnNnUXtjE"
      },
      "outputs": [],
      "source": [
        "## DA MUSIC\n",
        "class DA_Music_VarD(Model):\n",
        "    def __init__(self, lr, optimizer, M, n_angles_grid, A_grid, n_src_max):\n",
        "        super().__init__(lr)\n",
        "\n",
        "        self.M = M\n",
        "        # M : num sensors\n",
        "        self.BatchNorm = nn.BatchNorm1d(2*M)\n",
        "        self.gru = nn.GRU(2*M, 2*M, batch_first=True)\n",
        "        self.fc = nn.Linear(2*M, 2*M*M)\n",
        "\n",
        "        spec_len = n_angles_grid\n",
        "        n = 2*M\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(spec_len, n), nn.ReLU(),\n",
        "            nn.Linear(n, n), nn.ReLU(),\n",
        "            nn.Linear(n, n), nn.ReLU(),\n",
        "            nn.Linear(n, n_src_max)\n",
        "        )\n",
        "\n",
        "        self.A = torch.tensor(A_grid, dtype=torch.complex64, device=self.device)\n",
        "        self.A = self.A.swapaxes(0, 1).unsqueeze(2)\n",
        "        self.AH = self.A.swapaxes(1, 2).conj()\n",
        "\n",
        "        self.configure_optimizer(optimizer)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def loss(self, Y, Y_hat, X_d):\n",
        "        return loss_varD(Y.cpu(), Y_hat.cpu(), X_d).to(self.device)\n",
        "\n",
        "    def forward(self, X, X_d):\n",
        "        M = self.M\n",
        "        # X.shape = (B, M, T)\n",
        "        # X.shape = (B, 2*M, T)     cat(real, imag)\n",
        "        # ----------X.shape = (B, T, 2*M)\n",
        "        X = self.BatchNorm(X).swapaxes(1, 2)    # (B, T, 2*M)\n",
        "\n",
        "        y, _ = self.gru(X)\n",
        "        # print(y.shape)\n",
        "        y = y[:, -1, :]\n",
        "        y = self.fc(y)\n",
        "        y = y.reshape((-1, 2*M, M))\n",
        "        y = torch.complex(y[:, :M, :], y[:, M:, :])\n",
        "\n",
        "        Q, _, _ = torch.svd(y)\n",
        "        ## Qn = Q[:, :, D:]\n",
        "        # print(Qn.shape)\n",
        "\n",
        "        # QnQnH = torch.cat([(q @ q.conj().T).unsqueeze(0) for q in Qn])\n",
        "        QnQnH = torch.cat([(Q[i][:, X_d[i]:] @ Q[i][:, X_d[i]:].conj().T).unsqueeze(0) for i in range(Q.shape[0])])\n",
        "        QnQnH = QnQnH.unsqueeze(1)\n",
        "\n",
        "        spec = self.AH @ QnQnH @ self.A\n",
        "        spec = spec.squeeze()\n",
        "        spec = 1 / torch.abs(spec)\n",
        "        # find doa\n",
        "        y = self.net(spec)\n",
        "        return y\n",
        "\n",
        "    def fit_epoch(self):\n",
        "        self.train()\n",
        "        epoch_loss_avg = 0\n",
        "        for X, X_d, X_R, Y in tqdm(self.train_dataloader):\n",
        "            if self.gpu_is_available:\n",
        "                X = X.to(self.device)\n",
        "                Y = Y.to(self.device)\n",
        "\n",
        "            Y_hat = self(X, X_d)\n",
        "            # loss = self.loss(Y, Y_hat)\n",
        "            loss = self.loss(Y, Y_hat, X_d)\n",
        "            # loss = torch.mean((Y - Y_hat) ** 2)\n",
        "            epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "            self.optim.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "\n",
        "        self.history['train_loss'].append(epoch_loss_avg / len(self.train_dataloader))\n",
        "\n",
        "        ## change lr\n",
        "        if self.lr_scheduler:\n",
        "            # self.lr = self.lr_scheduler(self.lr, self.epoch)\n",
        "            # self.optim.param_groups[0]['lr'] = self.lr\n",
        "            self.change_lr(self.lr_scheduler(self.lr, self.epoch))\n",
        "\n",
        "        if self.val_dataloader != None:\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                epoch_loss_avg = 0\n",
        "                for X, X_d, X_R, Y in self.val_dataloader:\n",
        "                    if self.gpu_is_available:\n",
        "                        X = X.to(self.device)\n",
        "                        Y = Y.to(self.device)\n",
        "                    Y_hat = self(X, X_d)\n",
        "\n",
        "                    loss = self.loss(Y, Y_hat, X_d)\n",
        "\n",
        "                    epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "                self.history['val_loss'].append(epoch_loss_avg / len(self.val_dataloader))\n",
        "\n",
        "    def predict(self, Y, Y_d):\n",
        "        ## Y complex Array output\n",
        "        Ynet = torch.tensor(\n",
        "                np.concatenate((np.real(Y), np.imag(Y)), axis=0),\n",
        "                dtype=torch.float32, device=self.device\n",
        "        ).unsqueeze(0)\n",
        "        # ).swapaxes(0, 1).unsqueeze(0)\n",
        "        self.eval()\n",
        "        theta_hat = self(Ynet, Y_d).cpu().detach().numpy()\n",
        "        return theta_hat\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjM2OgvdYilq",
        "outputId": "894f0ff4-0720-465e-a490-cb6d0979565f"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "n_angles_grid=angles_grid.shape[0]; print(n_angles_grid)\n",
        "A_grid = doa.A_grid\n",
        "da_music = DA_Music_VarD(lr=lr, optimizer=torch.optim.Adam,\n",
        "                        M=M, n_angles_grid=n_angles_grid, A_grid=A_grid,\n",
        "                        n_src_max=N_SRC_MAX\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtAf0KigYtgo",
        "outputId": "efc31d99-eeaf-4437-ed28-1373342cec69"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViJUg7_TSwJt",
        "outputId": "f331f876-a857-41c8-b423-2277dae9a370"
      },
      "outputs": [],
      "source": [
        "da_music.fit(10, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "vPuYQf9xVTyK",
        "outputId": "67e4c22c-76be-4b36-939f-ec113f79d815"
      },
      "outputs": [],
      "source": [
        "\n",
        "da_music.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA2VOCcLDdvD",
        "outputId": "635f6c85-b072-4218-802f-1f225c9231ec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoD0Jml6kLi_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqi8qtTH3MBM"
      },
      "source": [
        "## DCNTA-MUISIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RxobzBg3KpZ"
      },
      "outputs": [],
      "source": [
        "class NSFE_Block(nn.Module): # Noise Suppression and Feature Extraction Block\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(c_in, c_out, 3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv1d(c_out, c_out, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# c1 = nn.Conv1d(2*M, 4*M, 3, padding=1)\n",
        "c_in, c_out = 2*M, 2*M\n",
        "# v15\n",
        "class First_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        c = 2*M\n",
        "        f = [c, 2*c, 4*c, 8*c, 16*c]\n",
        "        pool = nn.MaxPool1d\n",
        "        self.net0 = nn.Sequential(\n",
        "            NSFE_Block(f[0], f[1]), # (B, 4*M, T)\n",
        "            pool(2),                # (B, 4*M, T/2)\n",
        "            NSFE_Block(f[1], f[2]), # (B, 8*M, T/2)\n",
        "            nn.AdaptiveAvgPool1d(1),# (B, 8*M)\n",
        "        )\n",
        "        self.net1 = nn.Sequential(\n",
        "            nn.Linear(f[2], 2*M*M),# (B, 2*M*M)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net0(x)\n",
        "        # y = torch.mean(y, axis=-1)\n",
        "        y = y.squeeze(-1)\n",
        "        # return y\n",
        "        y = self.net1(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlV37DSkykN1"
      },
      "outputs": [],
      "source": [
        "class DCNTA_MUSIC(Model):\n",
        "    def __init__(self, lr, optimizer, M, n_angles_grid, A_grid, n_src_max):\n",
        "        super().__init__(lr)\n",
        "\n",
        "        # M : num sensors\n",
        "        # self.BatchNorm = nn.BatchNorm1d(2*M)\n",
        "\n",
        "        self.net0 = First_Block()\n",
        "\n",
        "        spec_len = n_angles_grid\n",
        "        n = 2*M\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(spec_len, n), nn.ReLU(),\n",
        "            nn.Linear(n, n), nn.ReLU(),\n",
        "            nn.Linear(n, n), nn.ReLU(),\n",
        "            nn.Linear(n, n_src_max),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.A = torch.tensor(A_grid, dtype=torch.complex64, device=self.device)\n",
        "        self.A = self.A.swapaxes(0, 1).unsqueeze(2)\n",
        "        self.AH = self.A.swapaxes(1, 2).conj()\n",
        "\n",
        "        self.configure_optimizer(optimizer)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def loss(self, Y, Y_hat, X_d):\n",
        "        return loss_varD(Y.cpu(), Y_hat.cpu(), X_d).to(self.device)\n",
        "\n",
        "    def forward(self, X, X_d):\n",
        "        \n",
        "        # X = self.BatchNorm(X)   # (B, 2*M, T)\n",
        "        #.swapaxes(1, 2)    # (B, T, 2*M)\n",
        "\n",
        "        y = self.net0(X) # (B, 2*M*M)\n",
        "        \n",
        "        y = y.reshape((-1, 2*M, M)) # (B, 2*M, M)\n",
        "        \n",
        "        y = torch.complex(y[:, :M, :], y[:, M:, :]) # (B, M, M)\n",
        "        # print(y.shape)\n",
        "\n",
        "        Q, _, _ = torch.svd(y)\n",
        "        ## Qn = Q[:, :, D:]\n",
        "        # print(Qn.shape)\n",
        "\n",
        "        # QnQnH = torch.cat([(q @ q.conj().T).unsqueeze(0) for q in Qn])\n",
        "        QnQnH = torch.cat([(Q[i][:, X_d[i]:] @ Q[i][:, X_d[i]:].conj().T).unsqueeze(0) for i in range(Q.shape[0])])\n",
        "        QnQnH = QnQnH.unsqueeze(1)\n",
        "\n",
        "        spec = self.AH @ QnQnH @ self.A\n",
        "        spec = spec.squeeze()\n",
        "        spec = 1 / torch.abs(spec)\n",
        "        # find doa\n",
        "        y = self.net(spec)\n",
        "        return y\n",
        "\n",
        "    def fit_epoch(self):\n",
        "        self.train()\n",
        "        epoch_loss_avg = 0\n",
        "        for X, X_d, X_R, Y in tqdm(self.train_dataloader):\n",
        "            if self.gpu_is_available:\n",
        "                X = X.to(self.device)\n",
        "                Y = Y.to(self.device)\n",
        "\n",
        "            Y_hat = self(X, X_d)\n",
        "            # loss = self.loss(Y, Y_hat)\n",
        "            Y /= (np.pi / 2.0) # *************************************************\n",
        "            loss = self.loss(Y, Y_hat, X_d)\n",
        "            # loss = torch.mean((Y - Y_hat) ** 2)\n",
        "            epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "            self.optim.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "\n",
        "        self.history['train_loss'].append(epoch_loss_avg / len(self.train_dataloader))\n",
        "\n",
        "        ## change lr\n",
        "        if self.lr_scheduler:\n",
        "            # self.lr = self.lr_scheduler(self.lr, self.epoch)\n",
        "            # self.optim.param_groups[0]['lr'] = self.lr\n",
        "            self.change_lr(self.lr_scheduler(self.lr, self.epoch))\n",
        "\n",
        "        if self.val_dataloader != None:\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                epoch_loss_avg = 0\n",
        "                for X, X_d, X_R, Y in self.val_dataloader:\n",
        "                    if self.gpu_is_available:\n",
        "                        X = X.to(self.device)\n",
        "                        Y = Y.to(self.device)\n",
        "                    Y_hat = self(X, X_d)\n",
        "                    Y /= (np.pi / 2.0) # *************************************************\n",
        "                    loss = self.loss(Y, Y_hat, X_d)\n",
        "\n",
        "                    epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "                self.history['val_loss'].append(epoch_loss_avg / len(self.val_dataloader))\n",
        "\n",
        "    def predict(self, Y, Y_d):\n",
        "        ## Y complex Array output\n",
        "        Ynet = torch.tensor(\n",
        "                np.concatenate((np.real(Y), np.imag(Y)), axis=0),\n",
        "                dtype=torch.float32, device=self.device\n",
        "        ).unsqueeze(0)\n",
        "        # ).swapaxes(0, 1).unsqueeze(0)\n",
        "        self.eval()\n",
        "        theta_hat = self(Ynet, Y_d).cpu().detach().numpy()\n",
        "        return theta_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TG8KvvnzeKt",
        "outputId": "5ce90ecb-cda1-48a3-c21e-fde24ff387cb"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "n_angles_grid=angles_grid.shape[0]; print(n_angles_grid)\n",
        "A_grid = doa.A_grid\n",
        "dcnta = DCNTA_MUSIC(lr=lr, optimizer=torch.optim.Adam,\n",
        "                        M=M, n_angles_grid=n_angles_grid, A_grid=A_grid,\n",
        "                        n_src_max=N_SRC_MAX\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp-clkh97VWf",
        "outputId": "1475cd73-dafd-46bd-defe-301e35d6330c"
      },
      "outputs": [],
      "source": [
        "dcnta.fit(40, train_dataloader, val_dataloader)\n",
        "dcnta.fit(40, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "DC3i9CxP8ibN",
        "outputId": "0dcc37da-5198-4280-c8f5-151228a281cf"
      },
      "outputs": [],
      "source": [
        "dcnta.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQOIdnDD4874",
        "outputId": "ecd015dd-e87a-450f-bf70-442874430111"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKh2KAYaU7r0"
      },
      "source": [
        "## Trans-MUSIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs4iyGgOU-NS"
      },
      "outputs": [],
      "source": [
        "# Trans_MUSIC Source Code: https://github.com/jijunkai/Transformer_Music\n",
        "\n",
        "import math\n",
        "\n",
        "m = M\n",
        "r = angles_grid.shape[0]\n",
        "\n",
        "def ULA_action_vector(theta):\n",
        "    array = np.linspace(0, m, m, endpoint=False)\n",
        "    return np.exp(- 1j * np.pi * array * np.sin(theta))\n",
        "\n",
        "## -----------------------------------------------------\n",
        "a=torch.zeros([m,r])+1j*torch.zeros([m,r])\n",
        "for i in range(r):\n",
        "    # a[:,i] =torch.from_numpy(ULA_action_vector(array, angles[0,i]))\n",
        "    # a[:,i] =torch.from_numpy(ULA_action_vector(angles[0,i]))\n",
        "    a[:,i] =torch.from_numpy(ULA_action_vector(angles_grid[i]))\n",
        "a=torch.complex(a.real.float(),a.imag.float()).to(device)\n",
        "\n",
        "\n",
        "def calculate_spectrum(En):\n",
        "\n",
        "    H1=torch.matmul(En.to(device)@ torch.conj(En.permute(0,2,1)).to(device),a).to(device)\n",
        "\n",
        "    H2=torch.mul(H1,torch.conj(a))\n",
        "\n",
        "    H3=torch.sum(H2,dim=1)\n",
        "\n",
        "    return (1.0/abs(H3)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)  + self.pe[:x.size(0)].to(device)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "#**********************************#\n",
        "#   trans_music                    #\n",
        "#**********************************#\n",
        "\n",
        "class Trans_MUSIC(Model):\n",
        "\n",
        "    def __init__(self, lr, optimizer, m, n_src_max):\n",
        "\n",
        "        super().__init__(lr)\n",
        "\n",
        "        self.m=m\n",
        "\n",
        "        self.BN=torch.nn.BatchNorm1d(16).to(device)\n",
        "        # self.LN= torch.nn.LayerNorm(normalized_shape = [16]).to(device)\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(16)#Position embedding\n",
        "\n",
        "        encoder_layer=torch.nn.TransformerEncoderLayer(    #Define encoder layer\n",
        "            d_model=16,\n",
        "            nhead=8, ##The number of heads in a multi head attention model\n",
        "            dim_feedforward=1024, #Dimensions of feedforward network models\n",
        "            dropout=0, #Dropout value\n",
        "            activation=\"relu\",\n",
        "            layer_norm_eps=1e-05,\n",
        "            batch_first=True,\n",
        "            norm_first=False,\n",
        "            device=None,\n",
        "            dtype=None).to(device)\n",
        "\n",
        "\n",
        "        self.encoder=torch.nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=3,\n",
        "            norm=None).to(device)\n",
        "\n",
        "        self.input_linear = nn.Linear(in_features=16, out_features=128).to(device)\n",
        "\n",
        "        self.output = nn.Sequential(\n",
        "\n",
        "            # nn.Linear(in_features=360, out_features=16) ,\n",
        "            nn.Linear(in_features=N_ANGLES_GRID, out_features=16) ,\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Linear(in_features=16, out_features=16),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Linear(in_features=16, out_features=16) ,\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Linear(in_features=16, out_features=n_src_max)\n",
        "                ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "        # self.output_d = nn.Sequential(\n",
        "        #     nn.Linear(in_features=128, out_features=128),\n",
        "        #     nn.ReLU(inplace=False),\n",
        "        #     nn.Linear(in_features=128, out_features=128) ,\n",
        "        #     nn.ReLU(inplace=False),\n",
        "        #     nn.Linear(in_features=128, out_features=64),\n",
        "        #     nn.ReLU(inplace=False),\n",
        "        #     nn.Linear(in_features=64, out_features=32),\n",
        "        #     nn.ReLU(inplace=False),\n",
        "        #     nn.Linear(in_features=32, out_features=4)\n",
        "        #         ).to(device)\n",
        "\n",
        "        self.configure_optimizer(optimizer)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x, x_d):\n",
        "\n",
        "\n",
        "\n",
        "        #The input X is [size, 16200] batch_ Size=16, input dimension 16, sequence length 200\n",
        "\n",
        "\n",
        "        size=x.shape[0]#Get batch_ Size size\n",
        "\n",
        "        # x=x.permute(0,2,1).float().to(device)# Exchange dimension becomes [size, 200,16]\n",
        "\n",
        "        x=self.BN(x).to(device)#Become [size, 16200]\n",
        "\n",
        "        # x=self.LN(x.to(device)).to(device)\n",
        "\n",
        "\n",
        "        x=x.permute(2,0,1).float().to(device)# Exchange dimension becomes [200, size, 16]\n",
        "\n",
        "        #Position embedding\n",
        "        x=self.pos_encoder(x.to(device)).to(device)  #x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "\n",
        "        x=x.permute(1,0,2).float().to(device)# Exchange dimension becomes [size, 200,16]\n",
        "\n",
        "        x1=self.encoder(x.to(device) )    #Transformer_ Encoder network output becomes [size, 200,16]\n",
        "\n",
        "        x2=torch.mean(x1,dim=1) #Output becomes [size, 16]\n",
        "\n",
        "        x3=self.input_linear(x2).to(device) #The output is passed to a fully connected layer and becomes [size, 128]\n",
        "\n",
        "        vector=x3 #\n",
        "\n",
        "        x4=x3.reshape(size,16,8).to(device) #Change its mapping covariance to [size, 16,8]\n",
        "\n",
        "        # vector=x4  #CNN for classifier\n",
        "\n",
        "        x5=torch.complex(x4[ :,:8 ,:].to(device),x4[ :,8: ,:].to(device))    #feature vector  [size,8,8]\n",
        "\n",
        "\n",
        "        x6=calculate_spectrum(x5).to(device)  #Calculate spectrum\n",
        "\n",
        "        x7=x6.float().to(device)\n",
        "\n",
        "        x8=self.output(x7.to(device)).to(device)\n",
        "\n",
        "\n",
        "        # #Classifier for estimating D\n",
        "        # x9=x3  #[size,16]\n",
        "        # x9=x9.detach()#Truncated gradient flow\n",
        "        # x9=self.output_d(x9)\n",
        "\n",
        "\n",
        "        return x8 #,x9,vector\n",
        "    def loss(self, Y, Y_hat, X_d):\n",
        "        return loss_varD(Y.cpu(), Y_hat.cpu(), X_d).to(self.device)\n",
        "    def fit_epoch(self):\n",
        "        self.train()\n",
        "        epoch_loss_avg = 0\n",
        "        for X, X_d, X_R, Y in tqdm(self.train_dataloader):\n",
        "            if self.gpu_is_available:\n",
        "                X = X.to(self.device)\n",
        "                Y = Y.to(self.device)\n",
        "\n",
        "            Y_hat = self(X, X_d)\n",
        "            # loss = self.loss(Y, Y_hat)\n",
        "            loss = self.loss(Y, Y_hat, X_d)\n",
        "            # loss = torch.mean((Y - Y_hat) ** 2)\n",
        "            epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "            self.optim.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "\n",
        "        self.history['train_loss'].append(epoch_loss_avg / len(self.train_dataloader))\n",
        "\n",
        "        ## change lr\n",
        "        if self.lr_scheduler:\n",
        "            # self.lr = self.lr_scheduler(self.lr, self.epoch)\n",
        "            # self.optim.param_groups[0]['lr'] = self.lr\n",
        "            self.change_lr(self.lr_scheduler(self.lr, self.epoch))\n",
        "\n",
        "        if self.val_dataloader != None:\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                epoch_loss_avg = 0\n",
        "                for X, X_d, X_R, Y in self.val_dataloader:\n",
        "                    if self.gpu_is_available:\n",
        "                        X = X.to(self.device)\n",
        "                        Y = Y.to(self.device)\n",
        "                    Y_hat = self(X, X_d)\n",
        "\n",
        "                    loss = self.loss(Y, Y_hat, X_d)\n",
        "\n",
        "                    epoch_loss_avg += loss.detach().item()\n",
        "\n",
        "                self.history['val_loss'].append(epoch_loss_avg / len(self.val_dataloader))\n",
        "    def predict(self, Y, Y_d):\n",
        "        ## Y complex Array output\n",
        "        Ynet = torch.tensor(\n",
        "                np.concatenate((np.real(Y), np.imag(Y)), axis=0),\n",
        "                dtype=torch.float32, device=self.device\n",
        "        ).unsqueeze(0)\n",
        "        # ).swapaxes(0, 1).unsqueeze(0)\n",
        "        self.eval()\n",
        "        theta_hat = self(Ynet, Y_d).cpu().detach().numpy()\n",
        "        return theta_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDQyZ2O4VEay"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "trans_music = Trans_MUSIC(lr=lr, optimizer=torch.optim.Adam, m=M, n_src_max=N_SRC_MAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY29f_VThCFS",
        "outputId": "d9117ec8-803c-4b57-a0a9-9351164301d1"
      },
      "outputs": [],
      "source": [
        "trans_music.fit(80, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "zwcIROE4Echp",
        "outputId": "975cabce-ec11-4a8c-b8ec-e1c77777f843"
      },
      "outputs": [],
      "source": [
        "trans_music.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gYM58UaEm5B",
        "outputId": "ffed12e3-7396-4b74-9039-dd2fd27620a8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEFXHPRDyyX8",
        "outputId": "ecaa0fcf-586a-45ad-f6a4-f33d84156bb2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9A-jiyLx-DY1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
